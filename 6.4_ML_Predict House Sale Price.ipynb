{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font color='blue'> Machine Learning - Predict a Home's Sale Price </font> </center></h1>  \n",
    "\n",
    "***by Susan Fisher***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, a linear regression model will be built to predict a home's sale price.  Building the model will include feature engineering, feature selection, and training the model.  The validation method and number of K-folds will be selected.  The data is taken from the city of Ames, Iowa from 2006 to 2010.  \n",
    "\n",
    "Information on the dataset can be found here: https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627  \n",
    "The data dictionary is located here:  https://s3.amazonaws.com/dq-content/307/data_description.txt\n",
    "\n",
    "The target for the model will be a house's sale price, and the model's features will be all numeric columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Python libraries and read in the data file as 'df' dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Displays all columns of the dataframe\n",
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Name/Documents/PythonScripts/DataSets/AmesHousing.tsv',\n",
    "            delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Roof Style</th>\n",
       "      <th>Roof Matl</th>\n",
       "      <th>Exterior 1st</th>\n",
       "      <th>Exterior 2nd</th>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Heating QC</th>\n",
       "      <th>Central Air</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <th>Garage Type</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Garage Qual</th>\n",
       "      <th>Garage Cond</th>\n",
       "      <th>Paved Drive</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Stone</td>\n",
       "      <td>112.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>639.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Fa</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>P</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468.0</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>108.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>923.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Ex</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>791.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour Utilities Lot Config Land Slope Neighborhood  \\\n",
       "0   NaN       IR1          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "1   NaN       Reg          Lvl    AllPub     Inside        Gtl        NAmes   \n",
       "2   NaN       IR1          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "3   NaN       Reg          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "4   NaN       IR1          Lvl    AllPub     Inside        Gtl      Gilbert   \n",
       "\n",
       "  Condition 1 Condition 2 Bldg Type House Style  Overall Qual  Overall Cond  \\\n",
       "0        Norm        Norm      1Fam      1Story             6             5   \n",
       "1       Feedr        Norm      1Fam      1Story             5             6   \n",
       "2        Norm        Norm      1Fam      1Story             6             6   \n",
       "3        Norm        Norm      1Fam      1Story             7             5   \n",
       "4        Norm        Norm      1Fam      2Story             5             5   \n",
       "\n",
       "   Year Built  Year Remod/Add Roof Style Roof Matl Exterior 1st Exterior 2nd  \\\n",
       "0        1960            1960        Hip   CompShg      BrkFace      Plywood   \n",
       "1        1961            1961      Gable   CompShg      VinylSd      VinylSd   \n",
       "2        1958            1958        Hip   CompShg      Wd Sdng      Wd Sdng   \n",
       "3        1968            1968        Hip   CompShg      BrkFace      BrkFace   \n",
       "4        1997            1998      Gable   CompShg      VinylSd      VinylSd   \n",
       "\n",
       "  Mas Vnr Type  Mas Vnr Area Exter Qual Exter Cond Foundation Bsmt Qual  \\\n",
       "0        Stone         112.0         TA         TA     CBlock        TA   \n",
       "1         None           0.0         TA         TA     CBlock        TA   \n",
       "2      BrkFace         108.0         TA         TA     CBlock        TA   \n",
       "3         None           0.0         Gd         TA     CBlock        TA   \n",
       "4         None           0.0         TA         TA      PConc        Gd   \n",
       "\n",
       "  Bsmt Cond Bsmt Exposure BsmtFin Type 1  BsmtFin SF 1 BsmtFin Type 2  \\\n",
       "0        Gd            Gd            BLQ         639.0            Unf   \n",
       "1        TA            No            Rec         468.0            LwQ   \n",
       "2        TA            No            ALQ         923.0            Unf   \n",
       "3        TA            No            ALQ        1065.0            Unf   \n",
       "4        TA            No            GLQ         791.0            Unf   \n",
       "\n",
       "   BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF Heating Heating QC Central Air  \\\n",
       "0           0.0        441.0         1080.0    GasA         Fa           Y   \n",
       "1         144.0        270.0          882.0    GasA         TA           Y   \n",
       "2           0.0        406.0         1329.0    GasA         TA           Y   \n",
       "3           0.0       1045.0         2110.0    GasA         Ex           Y   \n",
       "4           0.0        137.0          928.0    GasA         Gd           Y   \n",
       "\n",
       "  Electrical  1st Flr SF  2nd Flr SF  Low Qual Fin SF  Gr Liv Area  \\\n",
       "0      SBrkr        1656           0                0         1656   \n",
       "1      SBrkr         896           0                0          896   \n",
       "2      SBrkr        1329           0                0         1329   \n",
       "3      SBrkr        2110           0                0         2110   \n",
       "4      SBrkr         928         701                0         1629   \n",
       "\n",
       "   Bsmt Full Bath  Bsmt Half Bath  Full Bath  Half Bath  Bedroom AbvGr  \\\n",
       "0             1.0             0.0          1          0              3   \n",
       "1             0.0             0.0          1          0              2   \n",
       "2             0.0             0.0          1          1              3   \n",
       "3             1.0             0.0          2          1              3   \n",
       "4             0.0             0.0          2          1              3   \n",
       "\n",
       "   Kitchen AbvGr Kitchen Qual  TotRms AbvGrd Functional  Fireplaces  \\\n",
       "0              1           TA              7        Typ           2   \n",
       "1              1           TA              5        Typ           0   \n",
       "2              1           Gd              6        Typ           0   \n",
       "3              1           Ex              8        Typ           2   \n",
       "4              1           TA              6        Typ           1   \n",
       "\n",
       "  Fireplace Qu Garage Type  Garage Yr Blt Garage Finish  Garage Cars  \\\n",
       "0           Gd      Attchd         1960.0           Fin          2.0   \n",
       "1          NaN      Attchd         1961.0           Unf          1.0   \n",
       "2          NaN      Attchd         1958.0           Unf          1.0   \n",
       "3           TA      Attchd         1968.0           Fin          2.0   \n",
       "4           TA      Attchd         1997.0           Fin          2.0   \n",
       "\n",
       "   Garage Area Garage Qual Garage Cond Paved Drive  Wood Deck SF  \\\n",
       "0        528.0          TA          TA           P           210   \n",
       "1        730.0          TA          TA           Y           140   \n",
       "2        312.0          TA          TA           Y           393   \n",
       "3        522.0          TA          TA           Y             0   \n",
       "4        482.0          TA          TA           Y           212   \n",
       "\n",
       "   Open Porch SF  Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area Pool QC  \\\n",
       "0             62               0           0             0          0     NaN   \n",
       "1              0               0           0           120          0     NaN   \n",
       "2             36               0           0             0          0     NaN   \n",
       "3              0               0           0             0          0     NaN   \n",
       "4             34               0           0             0          0     NaN   \n",
       "\n",
       "   Fence Misc Feature  Misc Val  Mo Sold  Yr Sold Sale Type Sale Condition  \\\n",
       "0    NaN          NaN         0        5     2010       WD          Normal   \n",
       "1  MnPrv          NaN         0        6     2010       WD          Normal   \n",
       "2    NaN         Gar2     12500        6     2010       WD          Normal   \n",
       "3    NaN          NaN         0        4     2010       WD          Normal   \n",
       "4  MnPrv          NaN         0        3     2010       WD          Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0     215000  \n",
       "1     105000  \n",
       "2     172000  \n",
       "3     244000  \n",
       "4     189900  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View few rows of the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Initial build of Functions </font>\n",
    "    \n",
    "This section is an initial build of the functions that will engineer features, select features, and train the model.  In the following sections of this project, the functions will be updated.\n",
    "\n",
    "There will be 3 functions:\n",
    "- transform_features():  engineers features\n",
    "- select_features():  select features\n",
    "- train_and_test():  selects a model type and validation method, and trains and tests the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SalePrice'\n",
    "# features = ['Gr Liv Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTION - transform_features():  engineers features**  \n",
    "Returns a transformed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTION - select_features():  select features**  \n",
    "\n",
    "Returns dataframe columns, 'Gr Liv Area' and 'SalePrice'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTION - train_and_test()**  \n",
    "\n",
    "- Initial function creates a Holdout validation method\n",
    "- Creates a training and testing datasets\n",
    "- Sets a Linear Regression model\n",
    "- Trains the model on numeric features (columns)\n",
    "- Returns RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(df):    \n",
    "    # Dataframe: select all numeric columns except Target column \n",
    "    df_numeric = df.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    # Define target\n",
    "    target = 'SalePrice'\n",
    "    # Define features, which are all numeric columns - target column\n",
    "    features = df_numeric.columns.drop(target)\n",
    "    \n",
    "    # Split dataframe in half and assign to TRAIN & TEST dataset\n",
    "    half_df = round(len(df)*0.5)\n",
    "    train = df[:half_df]\n",
    "    test = df[half_df:]\n",
    "        \n",
    "    # Train a Linear Regression model on TEST set using numeric_cols\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train[target])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[target], predictions)\n",
    "    rmse = mse**0.5\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57120.50729008638"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Feature Engineering </font>  \n",
    "\n",
    "Feature engineering will include dealing with missing values, creating new features, and removing features (columns).  Lastly, the transform_features() function will be updated with all the engineering.\n",
    "\n",
    "1. Missing values:  \n",
    "    a. All columns: drop columns that are >= 5% missing values  \n",
    "    b. Numerical columns: fill in missing values with the most common value (mode)  \n",
    "    c. Text columns: drop columns with >= 1 missing values  \n",
    "2. Create new features by adding or subtracting columns e.g. years might make more sense if it is subtracted from a current year\n",
    "3. Remove features (columns):  \n",
    "    a. That are not useful for the model  \n",
    "    b. That leak info about the sale i.e. information about the target that would not have been known at the time of prediction\n",
    "4. Lastly, update the transform_features() function with 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Feature Engineering:  Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of columns with missing values before dropping any columns\n",
    "df.isnull().sum().value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Columns: drop columns with missing values >= 5%\n",
    "null_percent = (df.isnull().sum()) / (len(df))\n",
    "null_five = (null_percent[null_percent >= 0.05]).index\n",
    "df = df.drop(null_five, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of columns with missing values after dropping columns\n",
    "df.isnull().sum().value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns: replace missing values with the most common value in the column\n",
    "numeric_cols = df.select_dtypes(include=['float', 'int'])\n",
    "df[numeric_cols.columns] = numeric_cols.fillna(numeric_cols.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Mas Vnr Type', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure',\n",
       "       'BsmtFin Type 1', 'BsmtFin Type 2', 'Electrical'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After dropping columns: number of columns with missing values, and column names\n",
    "print(df.isnull().sum().value_counts().count())\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-659ccc0fbd6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnull_percent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnull_count\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnull_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull_percent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mnull_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'null_df' is not defined"
     ]
    }
   ],
   "source": [
    "# For each column, view the number of missing values and the percent of missing values\n",
    "null_list = []\n",
    "cols_null = ['Mas Vnr Type', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure',\n",
    "       'BsmtFin Type 1', 'BsmtFin Type 2', 'Electrical']\n",
    "\n",
    "for col in cols_null:\n",
    "    null_count = df[col].isnull().sum()\n",
    "    null_percent = round(100 * null_count/(len(df)), 1)\n",
    "    null_list.append([col, null_count, null_percent])\n",
    "null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that contain missing values are likely not significantly impact a home's sale price, so they will be dropped.  As a reminder, the data dictionary can be found here:  https://s3.amazonaws.com/dq-content/307/data_description.txt\n",
    "\n",
    "Although, 'Electrical' column only has one missing value, the column is not thought to significantly impact a home's sale price, so the entire column will be dropped (vs dropping the row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text columns: drop columns with missing values >= 1\n",
    "object_cols = df.select_dtypes(include=['object'])\n",
    "null_object_col = object_cols.isnull().sum()\n",
    "isnull_object_col = null_object_col[null_object_col > 0]\n",
    "\n",
    "df.drop(isnull_object_col.index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify there are no missing values in the dataframe\n",
    "df.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Feature Engineering:  Create New Features**  \n",
    "\n",
    "Create new features by adding or subtracting columns.\n",
    "\n",
    "1. Create 'Years Before Sale' column: by subtracting 'Year Built' from 'Yr Sold'\n",
    "2. Create 'Years Since Remod' column: by taking the difference of 'Yr Sold' and 'Year Remod/Add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New Feature: 'Years Before Sale'\n",
    "df['Years Before Sale'] = df['Yr Sold'] - df['Year Built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New Feature: 'Years Since Remod'\n",
    "df['Years Since Remod'] = df['Yr Sold'] - df['Year Remod/Add']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Features: verify no negative values\n",
    "print(df['Years Before Sale'][df['Years Before Sale']<0])\n",
    "print(df['Years Since Remod'][df['Years Since Remod']<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Features: drop rows with negative values\n",
    "\n",
    "# Number of rows before dropping rows\n",
    "print(df.shape)\n",
    "\n",
    "# Drop rows with negative values\n",
    "df.drop([1702, 2180, 2181], axis=0, inplace=True)\n",
    "\n",
    "# Verify rows have been dropped\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Feature Engineering:  Remove Features**  \n",
    "\n",
    "1. Remove features that are not useful to the model: 'PID', and 'Order'\n",
    "2. Remone features that leak data about the final sale e.g. year the sale occurred: 'Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are not useful to the model: 'PID' and 'Order'\n",
    "df.drop(['PID', 'Order'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that leak data about the final sale: 'Mo Sold', 'Sale Condition',\n",
    "# 'Sale Type', 'Yr Sold'\n",
    "df.drop(['Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify columns have been dropped\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Feature Engineering:  update transform_features() function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    # All Columns: drop columns with missing values >= 5%\n",
    "    null_percent = (df.isnull().sum()) / (len(df))\n",
    "    null_five = (null_percent[null_percent >= 0.05]).index\n",
    "    df = df.drop(null_five, axis=1)\n",
    "\n",
    "    # Numeric columns: replace missing values with the most common value\n",
    "    # in the column.\n",
    "    numeric_cols = df.select_dtypes(include=['float', 'int'])\n",
    "    df[numeric_cols.columns] = numeric_cols.fillna(numeric_cols.mode().iloc[0])\n",
    "\n",
    "    # Text columns: drop columns with missing values >= 1\n",
    "    object_cols = df.select_dtypes(include=['object'])\n",
    "    null_object_col = object_cols.isnull().sum()\n",
    "    isnull_object_col = null_object_col[null_object_col > 0]\n",
    "    df.drop(isnull_object_col.index, axis=1, inplace=True)\n",
    "\n",
    "    # Create New Features\n",
    "    df['Years Before Sale'] = df['Yr Sold'] - df['Year Built']\n",
    "    df['Years Since Remod'] = df['Yr Sold'] - df['Year Remod/Add']\n",
    "\n",
    "    # Drop negative values\n",
    "    df.drop([1702, 2180, 2181], axis=0, inplace=True)\n",
    "\n",
    "    # Remove columns that are not useful to the model: 'PID' and 'Order'\n",
    "    df.drop(['PID', 'Order'], axis=1, inplace=True)\n",
    "    # Remove columns that leak data about the final sale: 'Mo Sold',\n",
    "    # 'Sale Condition', 'Sale Type', 'Yr Sold'\n",
    "    df.drop(['Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset dataframe, df, by reading the file in again.\n",
    "\n",
    "df = pd.read_csv('C:/Users/Name/Documents/PythonScripts/DataSets/AmesHousing.tsv',\n",
    "            delimiter='\\t')\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Feature Selection </font>  \n",
    "\n",
    "This section will check for collinarity or when features are highly correlated, and convert columns to categorical type.  \n",
    "\n",
    "When features are highly correlated then information can be duplicated or there is the potential of information overload.  \n",
    "\n",
    "Nominal columns such as zip code, jersey number, gender, etc. can be converted to categorical type.  The number of unique values in a column must be limited, otherwise, the final dataframe could have hundreds of columns. \n",
    "\n",
    "Feature Selection:\n",
    "1. Generate a correlation heatmap matrix to check data for collinearity\n",
    "2. Retain columns with a correlation coefficient above a certain limit\n",
    "3. Convert object columns to categorical data type \n",
    "4. Update select_features() function to include the feature selections 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Feature Selection:  correlation heatmap matrix of the numerical features in the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe in half and assign to TRAIN & TEST dataset\n",
    "half_df = round(len(transform_df)*0.5)\n",
    "train = transform_df[:half_df]\n",
    "test = transform_df[half_df:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_df dataset: select numeric features/columns\n",
    "df_numeric = transform_df.select_dtypes(include=['integer', 'float'])\n",
    "\n",
    "# Find correlations between target, 'SalePrice', and numeric columns\n",
    "corr_coeffs = df_numeric.corr()['SalePrice'].abs().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of numeric correlations, where correlations >= 0.5\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_fifty = corr_coeffs[corr_coeffs < 0.5]\n",
    "corr_matrix = train[corr_fifty.index].corr().abs()\n",
    "\n",
    "sns.heatmap(corr_matrix,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_one = train[['TotRms AbvGrd', 'Bedroom AbvGr', '2nd Flr SF']].corr()\n",
    "print(corr_one, '\\n')\n",
    "\n",
    "corr_two = train[['Bsmt Full Bath', 'BsmtFin SF 1']].corr()\n",
    "print(corr_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the correlation heatmap matrix, the most highly correlated features are:\n",
    "- Bedroom AbvGr and TotRms AbvGrd:  correlation coefficient=0.66\n",
    "- Bsmt Full Bath and BsmtFin SF 1 (finished square feet):  correlation coefficient=0.65\n",
    "- 2nd Flr SF (square feet) and TotRms AbvGrd:  correlation coefficient=0.57\n",
    "\n",
    "It is understandable that the features would be well correlated, though the data is not duplicated.  Also, the correlation coefficients are less than 0.7, or not highly correlated.  So the columns will be retained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Feature Selection:  retain columns with a correlation coefficient above 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain colums with correlations >= 0.5 with 'SalePrice', drop other columns\n",
    "\n",
    "# transform_df size before dropping columns\n",
    "print(transform_df.shape)\n",
    "\n",
    "# Drop columns with correlation < 0.5 with 'SalePrice'\n",
    "transform_df = transform_df.drop(corr_coeffs[corr_coeffs < 0.5].index, axis=1)\n",
    "\n",
    "# Verify columns were dropped\n",
    "print(transform_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Feature Selection:  convert columns to categorical data type**  \n",
    "\n",
    "Convert features or columns to categorical data type:\n",
    "- Create a list of nominal column names and filter the dataframe by nominal columns  \n",
    "- Filter the dataframe with nominal columns that have < 10 unique values  \n",
    "- Convert object type columns to categorical type  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the data documentation, create a list of nominal columns\n",
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \n",
    "                    \"Land Contour\", \"Lot Config\", \"Neighborhood\", \"Condition 1\",\n",
    "                    \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\",\n",
    "                    \"Roof Matl\", \"Exterior 1st\", \"Exterior 2nd\", \"Mas Vnr Type\",\n",
    "                    \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transform_df dataframe cannot be filtered with nominal_features list;\n",
    "# Python returns an error if the list contains column names that are not in transform_df.\n",
    "# So create a list of column names that are in both nominal features list and in transform_df dataframe.\n",
    "\n",
    "nominal_cols_df = []\n",
    "for col in nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        nominal_cols_df.append(col)\n",
    "\n",
    "print(len(nominal_features))\n",
    "print(len(nominal_cols_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep nominal_cols_df features with < 10 unique values\n",
    "\n",
    "## Create list of the count of unique values of each feature in nominal_cols_df\n",
    "unique_counts = []\n",
    "for col in nominal_cols_df:\n",
    "    count = transform_df[col].value_counts().count()\n",
    "    unique_counts.append(count)\n",
    "\n",
    "s_unique_counts = pd.Series(unique_counts, index=nominal_cols_df)\n",
    "\n",
    "## Filter unique counts > 10, which will be used to drop columns from the dataframe\n",
    "drop_nonuniq_cols = s_unique_counts[s_unique_counts > 10].index\n",
    "\n",
    "## In transform_df, drop nominal_cols_df with > 10 unique values\n",
    "print(transform_df.shape)\n",
    "transform_df = transform_df.drop(drop_nonuniq_cols, axis=1)\n",
    "print(transform_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert remaining object columns to categorical type\n",
    "obj_cols = transform_df.select_dtypes(include=['object'])\n",
    "for col in obj_cols:\n",
    "    transform_df[col] = transform_df[col].astype('category')\n",
    "\n",
    "transform_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy columns and add back to the dataframe, and Drop the obj_cols\n",
    "transform_df = pd.concat([transform_df,\n",
    "                         pd.get_dummies(transform_df.select_dtypes(include=['category']))\n",
    "                         ],\n",
    "                        axis=1).drop(obj_cols, axis=1)\n",
    "\n",
    "print(transform_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Feature Selection:  update select_features() function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df, coeff_threshold=0.5, uniq_threshold=10):   \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \n",
    "                    \"Land Contour\", \"Lot Config\", \"Neighborhood\", \"Condition 1\",\n",
    "                    \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\",\n",
    "                    \"Roof Matl\", \"Exterior 1st\", \"Exterior 2nd\", \"Mas Vnr Type\",\n",
    "                    \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "    # Create a new list of column names that are in nominal features list\n",
    "    # and in df\n",
    "    nominal_cols_df = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            nominal_cols_df.append(col)\n",
    "\n",
    "    # Only keep nominal_cols_df features with < 10 unique values\n",
    "    ## Create list of the count of unique values of each features in nominal_cols_df\n",
    "    unique_counts = []\n",
    "    for col in nominal_cols_df:\n",
    "        count = df[col].value_counts().count()\n",
    "        unique_counts.append(count)\n",
    "    s_unique_counts = pd.Series(unique_counts, index=nominal_cols_df)\n",
    "    ## Filter unique counts > 10, which will be used to drop columns from the dataframe\n",
    "    drop_nonuniq_cols = s_unique_counts[s_unique_counts > 10].index\n",
    "    ## In transform_df, drop nominal_cols_df with > 10 unique values\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "\n",
    "    # Convert remaining object columns to categorical type\n",
    "    obj_cols = df.select_dtypes(include=['object'])\n",
    "    for col in obj_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    # Create dummy columns and add back to the dataframe, and Drop the obj_cols\n",
    "    df = pd.concat([df,\n",
    "                    pd.get_dummies(df.select_dtypes(include=['category']))\n",
    "                    ],\n",
    "                   axis=1).drop(obj_cols, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Train and Test </font>  \n",
    "\n",
    "This section will update the train_and_test() function.  The function selects a model type and validation method, and trains and tests the model.  The dataframe will be split into training and testing datasets.  Let v be the type of validation, and k is the number of folds or the number of times to split the dataframe into training and testing datasets.  The train_and_test() function returns RMSE.  \n",
    "\n",
    "The function will contain three types of validation methods:\n",
    "- for v=0, apply Holdout validation:  split data into 50:50 Training:Testing datasets (the existing function applies Holdout)  \n",
    "- for v=1 apply Simple Cross Validation:  randomize dataset, split data into 50:50 Training:Testing datasets; and Train model on each set of data.\n",
    "- for v>1, apply K-fold Cross Validation:  randomize dataset, and split data into k number of folds.  Train model on k - 1 folds.  Test model on kth fold.  Repeat until each k-fold has been the TEST set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Test: update train_and_test() function**  \n",
    "\n",
    "All final functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    # All Columns: drop columns with missing values >= 5%\n",
    "    null_percent = (df.isnull().sum()) / (len(df))\n",
    "    null_five = (null_percent[null_percent >= 0.05]).index\n",
    "    df = df.drop(null_five, axis=1)\n",
    "\n",
    "    # Numeric columns: replace missing values with the most common value\n",
    "    # in the column.\n",
    "    numeric_cols = df.select_dtypes(include=['float', 'int'])\n",
    "    df[numeric_cols.columns] = numeric_cols.fillna(numeric_cols.mode().iloc[0])\n",
    "\n",
    "    # Text columns: drop columns with missing values >= 1\n",
    "    object_cols = df.select_dtypes(include=['object'])\n",
    "    null_object_col = object_cols.isnull().sum()\n",
    "    isnull_object_col = null_object_col[null_object_col > 0]\n",
    "    df.drop(isnull_object_col.index, axis=1, inplace=True)\n",
    "\n",
    "    # Create New Features\n",
    "    df['Years Before Sale'] = df['Yr Sold'] - df['Year Built']\n",
    "    df['Years Since Remod'] = df['Yr Sold'] - df['Year Remod/Add']\n",
    "\n",
    "    # Drop negative values\n",
    "    df.drop([1702, 2180, 2181], axis=0, inplace=True)\n",
    "\n",
    "    # Remove columns that are not useful to the model: 'PID' and 'Order'\n",
    "    df.drop(['PID', 'Order'], axis=1, inplace=True)\n",
    "    # Remove columns that leak data about the final sale: 'Mo Sold',\n",
    "    # 'Sale Condition', 'Sale Type', 'Yr Sold'\n",
    "    df.drop(['Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df, coeff_threshold=0.5, uniq_threshold=10):   \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \n",
    "                    \"Land Contour\", \"Lot Config\", \"Neighborhood\", \"Condition 1\",\n",
    "                    \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\",\n",
    "                    \"Roof Matl\", \"Exterior 1st\", \"Exterior 2nd\", \"Mas Vnr Type\",\n",
    "                    \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "    # Create a new list of column names that are in nominal features list\n",
    "    # and in df\n",
    "    nominal_cols_df = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            nominal_cols_df.append(col)\n",
    "\n",
    "    # Only keep nominal_cols_df features with < 10 unique values\n",
    "    ## Create list of the count of unique values of each features in nominal_cols_df\n",
    "    unique_counts = []\n",
    "    for col in nominal_cols_df:\n",
    "        count = df[col].value_counts().count()\n",
    "        unique_counts.append(count)\n",
    "    s_unique_counts = pd.Series(unique_counts, index=nominal_cols_df)\n",
    "    ## Filter unique counts > 10, which will be used to drop columns from the dataframe\n",
    "    drop_nonuniq_cols = s_unique_counts[s_unique_counts > 10].index\n",
    "    ## In transform_df, drop nominal_cols_df with > 10 unique values\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "\n",
    "    # Convert remaining object columns to categorical type\n",
    "    obj_cols = df.select_dtypes(include=['object'])\n",
    "    for col in obj_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    # Create dummy columns and add back to the dataframe, and Drop the obj_cols\n",
    "    df = pd.concat([df,\n",
    "                    pd.get_dummies(df.select_dtypes(include=['category']))\n",
    "                    ],\n",
    "                   axis=1).drop(obj_cols, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(df, v, k):  \n",
    "    # Dataframe: select all numeric columns except Target column \n",
    "    df_numeric = df.select_dtypes(include=['integer', 'float'])    \n",
    "    # Define Target\n",
    "    target = 'SalePrice'\n",
    "    # Define features, which are all numeric columns - target column\n",
    "    features = df_numeric.columns.drop(target)\n",
    "    \n",
    "    # Instantiate an empty Linear Regression model \n",
    "    lr = LinearRegression()\n",
    "        \n",
    "    # Train a Linear Regression model on TEST set using numeric_cols\n",
    "    # v=0: apply Holdout validation; 50:50 split of data Train:Test\n",
    "    if v == 0:         \n",
    "        # 50:50 split of data into TRAIN & TEST dataset\n",
    "        half_df = round(len(df)*0.5)\n",
    "        train = df[:half_df]\n",
    "        test = df[half_df:]\n",
    "    \n",
    "        # Fit to TRAIN data, & Make predictions on the model using TEST data\n",
    "        lr.fit(train[features], train[target])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test[target], predictions)\n",
    "        rmse = mse**0.5\n",
    "        return rmse\n",
    "\n",
    "    # v=1:apply Simple Cross Validation; \n",
    "    if v == 1: \n",
    "        # Randomize data, and 50:50 split of data into TRAIN & TEST dataset\n",
    "        # Data must be split perfectly in half, else function does Not work\n",
    "        df = df.sample(frac=1, random_state=1)\n",
    "        if (len(df) % 2) != 0:\n",
    "            drop_index = np.random.choice(df.index, 1, replace=False)\n",
    "            df.drop(drop_index, axis=0, inplace=True) \n",
    "        half_df = round(len(df)*0.5)\n",
    "        train = df[:half_df]\n",
    "        test = df[half_df:]\n",
    "        \n",
    "        # Train on 'train', Test on 'test'\n",
    "        # Fit or train model on TRAIN data; & make predictions or test model with TEST data\n",
    "        lr.fit(train[features], train[target])\n",
    "        predictions_one = lr.predict(test[features])\n",
    "        mse_one = mean_squared_error(test[target], predictions_one)\n",
    "        rmse_one = mse_one**0.5\n",
    "    \n",
    "        # Fit/train model on TEST data; & make predictions on Model with TRAIN data\n",
    "        lr.fit(test[features], test[target])\n",
    "        predictions_two = lr.predict(train[features])\n",
    "        mse_two = mean_squared_error(train[target], predictions_one)\n",
    "        rmse_two = mse_two**0.5      \n",
    "    \n",
    "        # Return average RMSE\n",
    "        avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "        return avg_rmse\n",
    "\n",
    "    # v>1: apply K-fold cross validation; \n",
    "    else: \n",
    "        # Split data into k number of folds\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "        # K-fold Cross Validation\n",
    "        mse_values = cross_val_score(lr,\n",
    "                       df[features],\n",
    "                       df[target],\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=kf)\n",
    "        # cross_val_score() returns negative MSE values, so convert to positive values\n",
    "        abs_mse_values = abs(mse_values)\n",
    "        rmse_values = abs_mse_values**0.5\n",
    "        avg_rmse = np.mean(rmse_values)     # OR: avg_rmse = rmse_values.mean()     \n",
    "        return avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Name/Documents/PythonScripts/DataSets/AmesHousing.tsv',\n",
    "            delimiter='\\t')\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select validation method (v) and number of K-folds (k)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df\n",
    "\n",
    "kfold = 2\n",
    "# Holdout Validation, v=0:\n",
    "rmse_zero = round(train_and_test(df, v=0, k=kfold))\n",
    "print(\"For holdout validation (v=0), and kfolds=2:  \", rmse_zero, '\\n')\n",
    "\n",
    "# Simple Cross Validation, v=1:\n",
    "rmse_one = round(train_and_test(df, v=1, k=kfold))\n",
    "print(\"For simple cross validation (v=1), and kfolds=2:  \", rmse_one, '\\n', '\\n')\n",
    "\n",
    "# K-fold Cross Validation, v>1:\n",
    "kfold_cross_validation = 2\n",
    "rmse_two_dict = dict()\n",
    "for k in range(2,8):\n",
    "    rmse_two = train_and_test(df, kfold_cross_validation, k)  \n",
    "    rmse_two = round(rmse_two)\n",
    "    rmse_two_dict[k] = rmse_two\n",
    "\n",
    "# Convert rmse_dict dictionary to dataframe\n",
    "rmse_two_df = pd.DataFrame(rmse_two_dict.items(),\n",
    "                       columns=['k-folds', 'rmse'])\n",
    "print(\"For k-fold cross validation (v>1), and varying k:  \")\n",
    "rmse_two_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the validation method and number of K-folds based on the Root Mean Square Error, RMSE.  \n",
    "1. For **Holdout validation**, the data is split into two sets, so K-folds is 2.  This method returned a high RMSE value of **57,116**. \n",
    "2. For **Simple Cross validation**, the data is also split into two sets, so K-folds is 2.  This method returned the highest RMSE value of **69,695**.  \n",
    "3. For **K-Fold Cross validation**, K-folds can vary.  Since this method returned the lowest RMSE values, then **this method is selected**.  With increasing K-folds from 2 to 6, the RMSE decreased from **29,216 to 28,016**.  On this trend, then there is a temptation to use a maximum number of K-folds.  However, considering both bias and variance error, there is a bias-variance tradeoff; i.e. as the bias error decreases, then the variance error increase, and vice versa.  As a rule, typically a **k=3 is selected**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> CONCLUSION </font>  \n",
    "\n",
    "The goal of this project was to create a model to predict home prices for Ames, Iowa.  A linear regression model was selected, then features were engineered, features were selected, the model was trained and tested, and the type of validation and the number of K-folds were selected. \n",
    "\n",
    "Feature engineering included dealing with missing values, creating new features, and removing features that are not useful or leak information about the home's sale price.  Feature selection consisted of creating a correlation heatmap, and converting select features to categorical.  \n",
    "\n",
    "The K-fold cross validation method yields the lowest RMSE and a typical value of number of K-folds of 3 was selected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
